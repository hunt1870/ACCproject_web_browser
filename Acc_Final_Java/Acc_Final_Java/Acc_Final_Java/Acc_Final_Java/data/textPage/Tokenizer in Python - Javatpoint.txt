https://www.javatpoint.com/tokenizer-in-python::tokenizer in python - javatpoint ? scroll to top home python if else for loop function array string regex list set tuple dictionary programs numpy interview questions python tutorial python tutorial python features python history python applications python install python example python variables python data types python keywords python literals python operators python comments python if else python loops python for loop python while loop python break python continue python pass python strings python lists python tuples python list vs tuple python sets python dictionary python functions python built-in functions python lambda functions python files i/o python modules python exceptions python date python regex python sending email read csv file write csv file read excel file write excel file python assert python list comprehension python collection module python math module python os module python random module python statistics module python sys module python ides python arrays command line arguments python magic method python stack & queue pyspark mllib python decorator python generators web scraping using python python json python itertools python multiprocessing how to calculate distance between two points using geopy gmail api in python how to plot the google map using folium package in python grid search in python python high order function nsetools in python python program to find the nth fibonacci number python opencv object detection python simpleimputer module second largest number in python python oops python oops concepts python object class python constructors python inheritance abstraction in python python mysql environment setup database connection creating new database creating tables insert operation read operation update operation join operation performing transactions python mongodb python mongodb python sqlite python sqlite python questions how to install python in windows how to reverse a string in python how to read csv file in python how to run python program how to take input in python how to convert list to string in python how to append element in the list how to compare two lists in python how to convert int to string in python how to create a dictionary in python how to create a virtual environment in python how to declare a variable in python how to install matplotlib in python how to install opencv in python how to print in same line in python how to read json file in python how to read a text file in python how to use for loop in python is python scripting language how long does it take to learn python how to concatenate two strings in python how to connect database in python how to convert list to dictionary in python how to declare a global variable in python how to reverse a number in python what is an object in python which is the fastest implementation of python how to clear python shell how to create a dataframes in python how to develop a game in python how to install tkinter in python how to plot a graph in python how to print pattern in python how to remove an element from a list in python how to round number in python how to sort a dictionary in python strong number in python how to convert text to speech in python bubble sort in python logging in python insertion sort in python binary search in python linear search in python python vs scala queue in python stack in python heap sort in python palindrome program in python program of cumulative sum in python merge sort in python python matrix python unit testing forensics & virtualization best books to learn python best books to learn django gcd of two number in python python program to generate a random string how to one hot encode sequence data in python how to write square root in python pointer in python python 2d array python memory management python libraries for data visualization how to call a function in python git modules in python top python frameworks for gaming python audio modules wikipedia module in python python random randrange() permutation and combination in python getopt module in python merge two dictionaries in python multithreading in python 3 static in python how to get the current date in python argparse in python python tqdm module caesar cipher in python tokenizer in python how to add two lists in python shallow copy and deep copy in python atom python contains in python label encoding in python django vs. node js python frameworks how to create a vector in python using numpy pickle module of python how to convert bytes to string in python python program to find anagram how to convert list to set python vs javascript python holidays module fuzzywuzzy python library dask python dask python (part 2) mode in python menu-driven programs in python python array vs. list what is duck typing in python pep 8 in python python user groups basic commands in python f string in python how brython works how to use brython in the browser arima model in python python modulus operator matlab vs. python method resolution order in python monkey patching in python python __call__ method python heapq module python substring project ideas for python beginners python faker fizz-buzz program in python tabula python python program to print prime factor of given number python program to print pascal triangle namedtuple in python ordereddict in python t-test in python python return statement getter and setter in python enum class in python destructors in python curve fit in python converting csv to json in python underscore (_) in python set vs list in python locating and executing modules flatten list in python pair plot in python data hiding in python python program to find intersection of two lists how to create requirements.txt file in python tic-tac-toe in python python asynchronous programming - asyncio and await python main() function strftime() function in python verbose flag in python regex python ast module python requests module - http request shutil module in python python epoch to datetime python del statement looping technique in python metaprogramming with metaclasses in python precision handling in python python join list strip() function in python gradient descent algorithm prettytable in python sentiment analysis in python convert python list to numpy arrays traceback in python time clock() method in python deque in python dictionary comprehension in python python data analytics python seek() method ternary operator in python how to calculate the area of the circle using python how to write in text file using python python keyerror python super() function max() function in python fraction module in python popular python framework to build api how to check python version python %s - string formatting python seaborn library countplot in python range() vs. xrange() python wordcloud package in python convert dataframe into list anova test in python python program to find compound interest ansible in python python important tips and tricks python coroutines double underscores in python re.search() vs re.findall() in python regex how to install statsmodels in python cos in python vif in python __add__ method in python ethical hacking with python class variable vs instance perfect number in python eol in python python program to convert hexadecimal string to decimal string different methods in python for swapping two numbers without using third variable how to change plot size in matplotlib how to get the zip code in python eel in python assignment operators in python speech recognition python yield vs return in python graphene python name mangling in python python combination without itertools python comprehensions influxdb in python kafka tutorial in python augmented assignment expressions in python python (x,y) software python event-driven programming python semaphore python sorted reverse automorphic number in python sizeof in python python program for accepting the strings which contains all vowels class-based views vs function-based views how to handle cookies in django agg() function in python amicable numbers in python context manager in python create bmi calculator using python string to binary in python what is script mode in python best python libraries for machine learning python program to display calendar of given year how to open url in python broken pipe error in python code template for creating objects in python python program to calculate the best time to buy and sell stock tuple to string in python kadane's algorithm in python loggers in django weather app in django missing data conundrum: exploration and imputation techniques different methods of array rotation in python what is operator overloading in python defaultdict in python operator module in python spinner widget in the kivy library of python number plate recognition using python obfuscating a python program convert string to dictionary in python convert string to json in python dbscan algorithm in python how to write a code for printing the python exception/error hierarchy principal component analysis (pca) with python python program to find number of days between two given dates object recognition using python python vlc module set to list in python string to int in python internet of things with python python pysftp module amazing hacks of python average of list in python check installed modules in python choice() in python convert list to dataframe in python convert string to float in python decorators with parameters in python dynamic typing in python fabs in python how to remove decimal in python python closure python glob module writing a python module modules vs packages in python snmp module in python average of list in python append vs extend vs insert in python how to remove duplicates from a list in python remove multiple characters from a string in python shuffle in python floor() and ceil() functions in python sqrt(): math function of python python yfinance module difflib module in python convert the column type from string to datetime format in pandas dataframe python wxpython module random uniform python relational operators in python string to list in python chatbot in python how to convert float to int in python multiply all elements in list of python module vs function in python reverse a tuple in python tuple to dictionary in python datetime.timedelta() function of python python bio module python dash module how to select rows in pandas dataframe based on conditions typecasting in python dateutil module in python getpass module in python python wand library generate a qr code using python best python pdf library python cachetools module python cmdparser module python dash module python emoji module python nmap module python pylab module working with pdf files in python pdf handling in python manipulating pdf using python list all functions from a python module python list of dictionaries python shelve module creating interactive pdf forms using python python newspaper module how to connect wi-fi using python best python libraries used for ethical hacking windows system administration management using python indentation error in python python imaplib module python lxml module python mayavi module python os.listdir() method python modules for automation data visualization in python using bokeh library how to plot glyphs over a google map by using bokeh library in python how to plot a pie chart using bokeh library in python how to read contents of pdf using ocr in python grammar and spell checker in python converting html to pdf files using python readlines in python how to plot multiple lines on a graph using bokeh in python bokeh.plotting.figure.circle_x() function in python bokeh.plotting.figure.diamond_cross() function in python how to plot rays on a graph using bokeh in python image steganography using python inconsistent use of tabs and spaces in indentation how to plot multiple plots using bokeh in python how to make an area plot in python using bokeh python chempy module python memory-profiler module python phonenumbers module python platform module typeerror string indices must be an integer time series forecasting with prophet in python python pexpect module python optparse module int object is not iterable. python peewee library some cryptocurrency libraries for python building a blockchain using python huffman coding using python nested dictionary in python collections.userstring in python how to customize legends with matplotlib matplotlib legend in subplot morphological operations in image processing in python role of python in artificial intelligence python instagramy module python pprint module python primepy module android development using python python fbchat library artificial intelligence in cybersecurity: pitting algorithms vs algorithms understanding the recognition pattern of artificial intelligence when and how to leverage lambda architecture in big data why should we learn python for data science how to change the "legend" position in matplotlib how to check if element exists in list in python how to check spellings of given words using enchant in python python program to count the number of matching characters in a pair of string ping pong game using turtle in python python function to display calendar python program for calculating the sum of squares of first n natural numbers python program for how to check if a given number is fibonacci number or not randint() function in python visualize tiff file using matplotlib and gdal in python rarfile module in python stemming words using python python program for word guessing game blockchain in healthcare: innovations & opportunities snake game in python using turtle module how to find armstrong numbers between two given integers celery tutorial using python rsme - root mean square error in python building a twitter bot using python python progressbar module python pronouncing module python pyautogui module python pyperclip module how to generate uuid in python python top 10 libraries to learn in 2022 reading netcdf data using python the reprlib module in python how to take multiple input from user in python python zlib library python queue module python yaml parser effective root searching algorithms in python python bz2 module python ipaddress module python pylint module how to process xml in python bisect algorithm functions in python creating and updating powerpoint presentation using python how to change the size of figure drawn with matplotlib keyboard module in python python pyfiglet module creating an mcq quiz game in python statistic with python what is gil in python basic python for java developers how to download youtube videos using python scripts traffic flow simulation in python how to merge and sort two lists in python metacharacters in python write the python program to print all possible combination of integers modulo string formatting in python counters in python python pyautogui library how to draw the mandelbrot set in python python dbm module webcam motion detector in python graphql implementation in django how to implement protobuf in python pyqt library in python how to prettify data structures with pretty print in python encrypt a password in python using bcrypt pyramid framework in python building a telegram bot using python web2py framework in python python os.chdir() method balancing parentheses in python how to provide multiple constructors in python classes profiling the python code python tkinter (gui) python tkinter tkinter button tkinter canvas tkinter checkbutton tkinter entry tkinter frame tkinter label tkinter listbox tkinter menubutton tkinter menu tkinter message tkinter radiobutton tkinter scale tkinter scrollbar tkinter text tkinter toplevel tkinter spinbox tkinter panedwindow tkinter labelframe tkinter messagebox python web blocker introduction building python script script deployment on linux script deployment on windows python mcq python mcq python mcq part 2 related tutorials numpy tutorial django tutorial flask tutorial pandas tutorial pytorch tutorial pygame tutorial matplotlib tutorial opencv tutorial openpyxl tutorial python cgi python design pattern python programs python programs next ? ? prev tokenizer in python as we all know, there is an incredibly huge amount of text data available on the internet. but, most of us may not be familiar with the methods in order to start working with this text data. moreover, we also know that it is a tricky part to navigate our language's letters in machine learning as machines can recognize the numbers, not the letters. so, how the text data manipulation and cleaning are done to create a model? in order to answer this question, let us explore some wonderful concepts beneath natural language processing (nlp). solving an nlp problem is a process divided into multiple stages. first of all, we have to clean the unstructured text data before moving to the modeling stage. there are some key steps included in the data cleaning. these steps are as follows: word tokenization parts of speech prediction for every token text lemmatization stop words identification and removal, and a lot more. in the following tutorial, we will be learning a lot more about the very primary step known as tokenization. we will be understanding what tokenization is and why it is necessary for natural language processing (nlp). moreover, we will also be discovering some unique methods to execute tokenization in python. understanding tokenization tokenization is said to be dividing a large quantity of text into smaller fragments known as tokens. these fragments or tokens are pretty useful to find the patterns and are deliberated as the foundation step for stemming and lemmatization. tokenization also supports in substitution of sensitive data elements with non-sensitive ones. natural language processing (nlp) is utilized to create applications like text classification, sentimental analysis, intelligent chatbot, language translation, and many more. thus, it becomes important to understand the text pattern to achieve the purpose stated above. but for now, consider the stemming and lemmatization as the primary steps for cleaning the text data with the help of natural language processing (nlp). tasks like text classification or spam filtering use nlp along with deep learning libraries like keras and tensorflow. understanding the significance of tokenization in nlp in order to understand the significance of tokenization, let us consider the english language as an example. let us pick up any sentence and keep it in mind while understanding the following section. before processing a natural language, we have to identify the words constituting a string of characters. thus, tokenization appears out to be the most fundament step to proceed with natural language processing (nlp) this step is necessary as the text's actual meaning could be interpreted by analyzing each word present within the text. now, let us consider the following string as an example: my name is jamie clark. after performing the tokenization on the above string, we would be getting output as shown below: ['my', 'name', 'is', 'jamie', 'clark'] there are various uses for performing the operation. we can utilize the tokenized form in order to: count the total number of words in the text. count the word's frequency, i.e., the total number of times a specific word is present and a lot more. now, let us understand several ways to perform tokenization in natural language processing (nlp) in python. some methods to perform tokenization in python there are various unique methods of performing tokenization on textual data. some of these unique ways are described below: tokenization using the split() function in python the split() function is one of the basic methods available in order to split the strings. this function returns a list of strings after splitting the provided string by the particular separator. the split() function breaks a string at each space by default. however, we can specify the separator as per the need. let us consider the following examples: example 1.1: word tokenization using the split() function 
my_text = """let's play a game, would you rather! it's simple, you have to pick one or the other. let's get started. would you rather try vanilla ice cream or chocolate one? would you rather be a bird or a bat? would you rather explore space or the ocean? would you rather live on mars or on the moon? would you rather have many good friends or one very best friend? isn't it easy though? when we have less choices, it's easier to decide. but what if the options would be complicated? i guess, you pretty much not understand my point, neither did i, at first place and that led me to a bad decision."""

print(my_text.split())
 output: ['let's', 'play', 'a', 'game,', 'would', 'you', 'rather!', 'it's', 'simple,', 'you', 'have', 'to', 'pick', 'one', 'or', 'the', 'other.', 'let's', 'get', 'started.', 'would', 'you', 'rather', 'try', 'vanilla', 'ice', 'cream', 'or', 'chocolate', 'one?', 'would', 'you', 'rather', 'be', 'a', 'bird', 'or', 'a', 'bat?', 'would', 'you', 'rather', 'explore', 'space', 'or', 'the', 'ocean?', 'would', 'you', 'rather', 'live', 'on', 'mars', 'or', 'on', 'the', 'moon?', 'would', 'you', 'rather', 'have', 'many', 'good', 'friends', 'or', 'one', 'very', 'best', 'friend?', 'isn't', 'it', 'easy', 'though?', 'when', 'we', 'have', 'less', 'choices,', 'it's', 'easier', 'to', 'decide.', 'but', 'what', 'if', 'the', 'options', 'would', 'be', 'complicated?', 'i', 'guess,', 'you', 'pretty', 'much', 'not', 'understand', 'my', 'point,', 'neither', 'did', 'i,', 'at', 'first', 'place', 'and', 'that', 'led', 'me', 'to', 'a', 'bad', 'decision.']
 explanation: in the above example, we have used the split() method in order to break the paragraph into smaller fragments or say words. similarly, we can also break the paragraph into sentences by specifying the separator as the parameter for the split() function. as we know, a sentence generally ends with a full stop "."; which means that we can utilize the "." as the separator to split the string. let us consider the same in the following example: example 1.2: sentence tokenization using the split() function 
my_text = """dreams. desires. reality. there is a fine line between dream to become a desire and a desire to become a reality but expectations are way far then the reality. nevertheless, we live in a world of mirrors, where we always want to reflect the best of us. we all see a dream, a dream of no wonder what; a dream that we want to be accomplished no matter how much efforts it needed but we try."""

print(my_text.split('. '))
 output: ['dreams', 'desires', 'reality', 'there is a fine line between dream to become a desire and a desire to become a reality but expectations are way far then the reality', 'nevertheless, we live in a world of mirrors, where we always want to reflect the best of us', 'we all see a dream, a dream of no wonder what; a dream that we want to be accomplished no matter how much efforts it needed but we try.']
 explanation: in the above example, we have used the split() function with the full stop (.) as its parameter in order to break the paragraph at the full stops. a major disadvantage of utilizing the split() function is that the function takes one parameter at a time. hence, we can only use a separator in order to split the string. moreover, the split() function does not consider the punctuations as the separate fragment. tokenization using regex (regular expressions) in python before moving onto the next method, let us understand the regular expression in brief. a regular expression, also known as regex, is a special sequence of characters that allows the users to find or match other strings or string sets with that sequence's help as a pattern. in order to start working with regex (regular expression), python provides the library known as re. the re library is one of the pre-installed libraries in python. let us consider the following examples based on word tokenization and sentence tokenization using the regex method in python. example 2.1: word tokenization using the regex method in python 
import re

my_text = """joseph arthur was a young businessman. he was one of the shareholders at ryan cloud's start-up with james foster and george wilson. the start-up took its flight in the mid-90s and became one of the biggest firms in the united states of america. the business was expanded in all major sectors of livelihood, starting from personal care to transportation by the end of 2000. joseph was used to be a good friend of ryan."""

my_tokens = re.findall
 output: ['joseph', 'arthur', 'was', 'a', 'young', 'businessman', 'he', 'was', 'one', 'of', 'the', 'shareholders', 'at', 'ryan', 'cloud', 's', 'start', 'up', 'with', 'james', 'foster', 'and', 'george', 'wilson', 'the', 'start', 'up', 'took', 'its', 'flight', 'in', 'the', 'mid', '90s', 'and', 'became', 'one', 'of', 'the', 'biggest', 'firms', 'in', 'the', 'united', 'states', 'of', 'america', 'the', 'business', 'was', 'expanded', 'in', 'all', 'major', 'sectors', 'of', 'livelihood', 'starting', 'from', 'personal', 'care', 'to', 'transportation', 'by', 'the', 'end', 'of', '2000', 'joseph', 'was', 'used', 'to', 'be', 'a', 'good', 'friend', 'of', 'ryan']
 explanation: in the above example, we have imported the re library in order to use its functions. we have then used the findall() function of the re library. this function helps the users to find all the words that match the pattern present in the parameter and stores them in the list. moreover, the "\w" is used to represent any word character, refers to alphanumeric (includes alphabets, numbers), and underscore (_). "+" indicates any frequency. thus, we have followed the [\w']+ pattern so that the program should look and find all the alphanumeric characters until it encounters any other one. now, let's have a look at sentence tokenization with the regex method. example 2.2: sentence tokenization using the regex method in python 
import re

my_text = """the advertisement was telecasted nationwide, and the product was sold in around 30 states of america. the product became so successful among the people that the production was increased. two new plant sites were finalized, and the construction was started. now, the cloud enterprise became one of america's biggest firms and the mass producer in all major sectors, from transportation to personal care. director of the cloud enterprise, ryan cloud, was now started getting interviewed over his success stories. many popular magazines were started publishing critiques about him."""

my_sentences = re.compile('[.!?] ').split(my_text)
print(my_sentences)
 output: ['the advertisement was telecasted nationwide, and the product was sold in around 30 states of america', 'the product became so successful among the people that the production was increased', 'two new plant sites were finalized, and the construction was started', "now, the cloud enterprise became one of america's biggest firms and the mass producer in all major sectors, from transportation to personal care", 'director of the cloud enterprise, ryan cloud, was now started getting interviewed over his success stories', 'many popular magazines were started publishing critiques about him.']
 explanation: in the above example, we have used the compile() function of the re library with the parameter '[.?!]' and used the split() method to separator the string from the specified separator. as a result, the program splits the sentences as soon as it encounters any of these characters. tokenization using natural language toolkit in python natural language toolkit, also known as nltk, is a library written in python. nltk library is generally used for symbolic and statistical natural language processing and works well with textual data. natural language toolkit (nltk) is a third-party library that can be installed using the following syntax in a command shell or terminal: 
$ pip install --user -u nltk
 in order to verify the installation, one can import the nltk library in a program and execute it as shown below: 
import nltk
 if the program does not raise an error, then the library has been installed successfully. otherwise, it is recommended to follow the above installation procedure again and read the official documentation for more details. natural language toolkit (nltk) has a module named tokenize(). this module is further categorized into two sub-categories: word tokenize and sentence tokenize word tokenize: the word_tokenize() method is used to split a string into tokens or say words. sentence tokenize: the sent_tokenize() method is used to split a string or paragraph into sentences. let us consider some example based on these two methods: example 3.1: word tokenization using the nltk library in python 
from nltk.tokenize import word_tokenize

my_text = """the advertisement was telecasted nationwide, and the product was sold in around 30 states of america. the product became so successful among the people that the production was increased. two new plant sites were finalized, and the construction was started. now, the cloud enterprise became one of america's biggest firms and the mass producer in all major sectors, from transportation to personal care. director of the cloud enterprise, ryan cloud, was now started getting interviewed over his success stories. many popular magazines were started publishing critiques about him."""

print(word_tokenize(my_text))
 output: ['the', 'advertisement', 'was', 'telecasted', 'nationwide', ',', 'and', 'the', 'product', 'was', 'sold', 'in', 'around', '30', 'states', 'of', 'america', '.', 'the', 'product', 'became', 'so', 'successful', 'among', 'the', 'people', 'that', 'the', 'production', 'was', 'increased', '.', 'two', 'new', 'plant', 'sites', 'were', 'finalized', ',', 'and', 'the', 'construction', 'was', 'started', '.', 'now', ',', 'the', 'cloud', 'enterprise', 'became', 'one', 'of', 'america', "'s", 'biggest', 'firms', 'and', 'the', 'mass', 'producer', 'in', 'all', 'major', 'sectors', ',', 'from', 'transportation', 'to', 'personal', 'care', '.', 'director', 'of', 'the', 'cloud', 'enterprise', ',', 'ryan', 'cloud', ',', 'was', 'now', 'started', 'getting', 'interviewed', 'over', 'his', 'success', 'stories', '.', 'many', 'popular', 'magazines', 'were', 'started', 'publishing', 'critiques', 'about', 'him', '.']
 explanation: in the above program, we have imported the word_tokenize() method from the tokenize module of the nltk library. thus, as a result, the method has broken the string into different tokens and stored it in a list. and at last, we have printed the list. moreover, this method includes the full stops and other punctuation marks as a separate token. example 3.1: sentence tokenization using the nltk library in python 
from nltk.tokenize import sent_tokenize

my_text = """the advertisement was telecasted nationwide, and the product was sold in around 30 states of america. the product became so successful among the people that the production was increased. two new plant sites were finalized, and the construction was started. now, the cloud enterprise became one of america's biggest firms and the mass producer in all major sectors, from transportation to personal care. director of the cloud enterprise, ryan cloud, was now started getting interviewed over his success stories. many popular magazines were started publishing critiques about him."""

print(sent_tokenize(my_text))
 output: ['the advertisement was telecasted nationwide, and the product was sold in around 30 states of america.', 'the product became so successful among the people that the production was increased.', 'two new plant sites were finalized, and the construction was started.', "now, the cloud enterprise became one of america's biggest firms and the mass producer in all major sectors, from transportation to personal care.", 'director of the cloud enterprise, ryan cloud, was now started getting interviewed over his success stories.', 'many popular magazines were started publishing critiques about him.']
 explanation: in the above program, we have imported the sent_tokenize() method from the tokenize module of the nltk library. thus, as a result, the method has broken the paragraph into different sentences and stored it in a list. and at last, we have printed the list. conclusion in the above tutorial, we have discovered the concepts of tokenization and its role in the overall natural language processing (nlp) pipeline. we have also discussed a few methods of tokenization (including the word tokenization and sentence tokenization) from a specific text or string in python. next topichow to add two lists in python ? prev next ? for videos join our youtube channel: join now feedback send your feedback to [email protected] help others, please share learn latest tutorials splunk spss swagger transact-sql tumblr reactjs regex reinforcement learning r programming rxjs react native python design patterns python pillow python turtle keras preparation aptitude reasoning verbal ability interview questions company questions trending technologies artificial intelligence aws selenium cloud computing hadoop reactjs data science angular 7 blockchain git machine learning devops b.tech / mca dbms data structures daa operating system computer network compiler design computer organization discrete mathematics ethical hacking computer graphics software engineering web technology cyber security automata c programming c++ java .net python programs control system data mining data warehouse javatpoint services javatpoint offers too many high quality services. mail us on [email protected], to get more information about given services. website designing website development java development php development wordpress graphic designing logo digital marketing on page and off page seo ppc content development corporate training classroom and online training data entry training for college campus javatpoint offers college campus training on core java, advance java, .net, android, hadoop, php, web technology and python. please mail your requirement at [email protected] duration: 1 week to 2 week like/subscribe us for latest updates or newsletter learn tutorialslearn javalearn data structureslearn c programminglearn c++ tutoriallearn c# tutoriallearn php tutoriallearn html tutoriallearn javascript tutoriallearn jquery tutoriallearn spring tutorial our websitesjavatpoint.comhindi100.comlyricsia.comquoteperson.comjobandplacement.com our services website development android development website designing digital marketing summer training industrial training college campus training contact address: g-13, 2nd floor, sec-3 noida, up, 201301, india contact no: 0120-4256464, 9990449935contact us subscribe us privacy policysitemap about me ? copyright 2011-2021 www.javatpoint.com. all rights reserved. developed by javatpoint.
